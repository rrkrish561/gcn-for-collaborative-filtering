{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for training and testing Graph Neural Network for Neural Collaborative Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from gncf import GNCF\n",
    "from graph_epinions_dataset import GraphEpinionsDataset\n",
    "from epinions_graph import *\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Load train data to determine train/test split\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "train_idx = len(train_data)\n",
    "\n",
    "# Return node features and mapping from user/item to index\n",
    "_, user_mapping = load_node_csv('data/all_data.csv', index_col='user')\n",
    "_, item_mapping = load_node_csv('data/all_data.csv', index_col='item')\n",
    "\n",
    "# Return edge index and edge attributes\n",
    "edge_index, edge_label = load_edge_csv('data/all_data.csv', \n",
    "                                      src_index_col='user', \n",
    "                                      src_mapping=user_mapping, \n",
    "                                      dst_index_col='item', \n",
    "                                      dst_mapping=item_mapping,\n",
    "                                      encoders={'label': IdentityEncoder(dtype=torch.long)})\n",
    "    \n",
    "\n",
    "data = HeteroData()\n",
    "data = data.to(device)\n",
    "data['user'].x = torch.arange(len(user_mapping))\n",
    "data['item'].x = torch.arange(len(item_mapping))\n",
    "data['user', 'rates', 'item'].edge_index = edge_index\n",
    "data['user', 'rates', 'item'].edge_label = edge_label\n",
    "\n",
    "train_data = data.clone()\n",
    "test_data = data.clone()\n",
    "\n",
    "# Partition in training and test set\n",
    "train_data['user', 'rates','item'].edge_index = data['user', 'rates', 'item'].edge_index[:, :train_idx]\n",
    "train_data['user', 'rates','item'].edge_label = data['user', 'rates', 'item'].edge_label[:train_idx]\n",
    "train_data['user', 'rates', 'item'].edge_label_index = data['user', 'rates', 'item'].edge_index[:, :train_idx]\n",
    "\n",
    "test_data['user', 'rates','item'].edge_index = data['user', 'rates', 'item'].edge_index[:, :train_idx]\n",
    "test_data['user', 'rates','item'].edge_label = data['user', 'rates', 'item'].edge_label[train_idx:]\n",
    "test_data['user', 'rates', 'item'].edge_label_index = data['user', 'rates', 'item'].edge_index[:, train_idx:]\n",
    "\n",
    "# Add a reverse edge for user aggregration/item modeling\n",
    "train_data = ToUndirected()(train_data)\n",
    "del train_data['item', 'rev_rates', 'user'].edge_label  # Remove \"reverse\" label.\n",
    "test_data = ToUndirected()(test_data)\n",
    "del test_data['item', 'rev_rates', 'user'].edge_label  # Remove \"reverse\" label.\n",
    "\n",
    "print(train_data)\n",
    "print(test_data)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, epochs=10):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
    "                    train_data['user', 'item'].edge_label_index)\n",
    "        target = (train_data['user', 'item'].edge_label).float()\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch + 1}/{epochs} Loss {loss.item()}')\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "num_users = len(user_mapping)\n",
    "num_items = len(item_mapping)\n",
    "user_emb_dim = 128\n",
    "item_emb_dim = 128\n",
    "hidden_channels = 32\n",
    "out_channels = 16\n",
    "metadata = train_data.metadata()\n",
    "\n",
    "# Create model\n",
    "model = GNCF(num_users, num_items, user_emb_dim, item_emb_dim, hidden_channels, out_channels, metadata)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "losses = train(model, optimizer, criterion, epochs=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
